{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective : test linear decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from pylec.optimize.batteries import OptimizeBatteries\n",
    "from pylec.forecast.manage import MultiModel\n",
    "from pylec.forecast.pipelines import PipelineNoExog, PipelineZenith\n",
    "from horizon.models import GAM, Perfect\n",
    "from pylec.control.matchsurplus import MatchSurplus\n",
    "from pylec.simulate import Simulation\n",
    "from pylec.scenarios import PVGISQuoilin, describe\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "layout = {\n",
    "    'showlegend': False,\n",
    "    'margin': {'b':10, 'l':10, 'r':10, 't':10},\n",
    "    'font': {'size': 19},\n",
    "    'xaxis': {'zerolinewidth': 2,  'zerolinecolor':'black'},\n",
    "    'yaxis': {'zerolinewidth': 2, 'zerolinecolor':'black'},\n",
    "    'template': 'plotly_white',\n",
    "}\n",
    "px.defaults.color_discrete_sequence = px.colors.qualitative.T10\n",
    "\n",
    "\n",
    "def distribution_plots(errors, ecdf_only=False):\n",
    "    if not ecdf_only:\n",
    "        fig = px.histogram(errors, barmode=\"overlay\", histnorm=\"percent\", marginal=\"box\")\n",
    "        fig.data[0].update({\"marker_opacity\": 1.0})\n",
    "        fig.data[1].update({\"boxpoints\": False})\n",
    "        fig.data[2].update({\"opacity\": 0.7})\n",
    "        fig.data[3].update({\"boxpoints\": False})\n",
    "        fig.update_layout(layout, showlegend=True,\n",
    "                          yaxis_title=\"Percentage [%]\", xaxis_title=\"U* - Uhat\",\n",
    "                          xaxis_range=[-0.5, 0.5])\n",
    "        fig.show()\n",
    "\n",
    "    fig = px.ecdf(errors, lines=True, markers=False)\n",
    "    fig.update_layout(layout, showlegend=True,\n",
    "                      yaxis_title=\"ECDF\", xaxis_title=\"U* - Uhat\",\n",
    "                      xaxis_range=[-1, 1], yaxis_dtick=0.1)\n",
    "    fig.update_traces(line_width=5)\n",
    "    fig.show()\n",
    "    \n",
    "    print(f\"Score before = {round(errors['Uhat=U (before)'].abs().sum(), 2)}, \\\n",
    "            Score after = {round(errors['Uhat=g() (after)'].abs().sum(), 2)}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Model and scenario\n",
    "\n",
    "- Perfect model\n",
    "- GAM forecast not adjusted\n",
    "- 15 days in june, 3kWh, 1.5kWp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true,
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "cons_gam = {\n",
    "    \"model\": GAM,\n",
    "    \"kwarg\": {\n",
    "        \"inputs\": [],\n",
    "        \"daily_seasonality\": True,\n",
    "        \"weekly_seasonality\": True,\n",
    "        \"seasonality_mode\": \"additive\",\n",
    "        \"changepoint_prior_scale\": 0.05,\n",
    "        \"seasonality_prior_scale\": 0.1,\n",
    "        \"uncertainty_samples\": 0,\n",
    "    },\n",
    "    \"pipeline\": PipelineNoExog,\n",
    "    \"target\": \"cons_id\",\n",
    "}\n",
    "\n",
    "prod_gam = {\n",
    "    \"model\": GAM,\n",
    "    \"kwarg\": {\n",
    "        \"inputs\": [\"clearsky_ghi\", \"zenith\"],\n",
    "        \"daily_seasonality\": True,\n",
    "        \"weekly_seasonality\": False,\n",
    "        \"seasonality_mode\": \"additive\",\n",
    "        \"changepoint_prior_scale\": 0.05,\n",
    "        \"seasonality_prior_scale\": 0.1,\n",
    "        \"uncertainty_samples\": 0,\n",
    "    },\n",
    "    \"pipeline\": PipelineZenith,\n",
    "    \"target\": \"prod_id\",\n",
    "}\n",
    "\n",
    "cons_perfect = {\n",
    "    \"model\": Perfect,\n",
    "    \"kwarg\": {\n",
    "        \"inputs\": [],\n",
    "    },\n",
    "    \"pipeline\": PipelineNoExog,\n",
    "    \"target\": \"cons_id\",\n",
    "}\n",
    "\n",
    "prod_perfect = {\n",
    "    \"model\": Perfect,\n",
    "    \"kwarg\": {\n",
    "        \"inputs\": [],\n",
    "    },\n",
    "    \"pipeline\": PipelineNoExog,\n",
    "    \"target\": \"prod_id\",\n",
    "}\n",
    "\n",
    "costs = {\n",
    "        \"grid_buy\": 0.1740,\n",
    "        \"grid_fee\": 0.0371,  # 0.0686 for the \"real turpe\"\n",
    "        \"battery_aging_cost\": 0.001\n",
    "}\n",
    "\n",
    "two_days = timedelta(days=2)\n",
    "one_day = timedelta(days=1)\n",
    "\n",
    "models = []\n",
    "names = []\n",
    "names.append(\"Perfect\")\n",
    "models.append(Simulation(\n",
    "    cons_model=MultiModel(**cons_perfect),\n",
    "    prod_model=MultiModel(**prod_perfect),\n",
    "    optim_model=OptimizeBatteries(**costs),\n",
    "    realtime_model=False,\n",
    "    optim_horizon=two_days,\n",
    "    optim_freq=one_day,\n",
    "))\n",
    "\n",
    "names.append(\"GAM_NOTadjusted\")\n",
    "models.append(Simulation(\n",
    "    cons_model=MultiModel(**cons_gam),\n",
    "    prod_model=MultiModel(**prod_gam),\n",
    "    optim_model=OptimizeBatteries(**costs),\n",
    "    realtime_model=False,\n",
    "    optim_horizon=two_days,\n",
    "    optim_freq=one_day,\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "start = datetime(2019, 4, 1, 0, 0, 0)\n",
    "end = start + timedelta(days=29+7, hours=23, minutes=45)\n",
    "\n",
    "scenario = PVGISQuoilin(\n",
    "    start=start,\n",
    "    end=end,\n",
    "    consumption_file=\"../../pylec/studies/data/Synthetic.Household.Profiles.h5\",\n",
    "    production_file=\"../../pylec/studies/data/Timeseries_45.187_5.737_SA_1kWp_crystSi_0_39deg_-6deg_2015_2015.csv\",\n",
    "    pv_kw=3.0,\n",
    "    batt_kw=2.5,\n",
    "    batt_kwh=5.0,\n",
    "    community_size=False,\n",
    "    consumption_ids=['2000989', '2001197', '2000914', '2001123', '2000964', '2001189', \n",
    "       '2001111', '2001179', '2000909', '2000918', '2000994', '2001107', '2000913',\n",
    "       '2001139', '2000960', '2001149', '2001165', '2000954', '2001114',\n",
    "       '2000926'],\n",
    "    apply_topology=True,\n",
    ")\n",
    "\n",
    "timeseries, topology = scenario.create()\n",
    "scenarios = [1]\n",
    "datas = [{\n",
    "    \"data\": timeseries.copy(),\n",
    "    \"topology\": topology.copy(),\n",
    "    \"start\": start,\n",
    "    \"end\": end\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true,
    "hide_input": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perfect\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f17dbba41c06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscenario\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscenario\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0m_time_elapsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Git/pylec/pylec/simulate.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, start, end, data, topology)\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forecast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0morder_book\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_participate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                 \u001b[0mschedules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder_book\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_mpctrigger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Git/pylec/pylec/simulate.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(self, predictions, order_book)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_optimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder_book\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder_book\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopology\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_setpoints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschedules\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Git/pylec/pylec/optimize/base.py\u001b[0m in \u001b[0;36msolve\u001b[0;34m(self, predictions, order_book, topology)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mnetloads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmembers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0massets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder_book\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopology\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_solve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetloads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmembers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0massets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder_book\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprepprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder_book\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopology\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Git/pylec/pylec/optimize/base.py\u001b[0m in \u001b[0;36mpostprocess\u001b[0;34m(self, model, predictions, order_book)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder_book\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mschedules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_timevar_from_pyomo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         schedules[\"schedules\"] = (\n\u001b[1;32m     63\u001b[0m             \u001b[0mschedules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"batteryin\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mschedules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"batteryout\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Git/pylec/pylec/optimize/utils.py\u001b[0m in \u001b[0;36mget_timevar_from_pyomo\u001b[0;34m(model, timeindex)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             results[var.name] = (\n\u001b[0;32m---> 74\u001b[0;31m                 \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"none\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m                 \u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0;34m.\u001b[0m\u001b[0munstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/jonathan/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/jonathan/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[0;34m(data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         ]\n\u001b[0;32m--> 287\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/jonathan/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype, verify_integrity)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcreate_block_manager_from_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/jonathan/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_arrays\u001b[0;34m(arrays, names, axes)\u001b[0m\n\u001b[1;32m   1699\u001b[0m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCPandasArray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1700\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1701\u001b[0;31m         \u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_form_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1702\u001b[0m         \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBlockManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1703\u001b[0m         \u001b[0mmgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/jonathan/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_form_blocks\u001b[0;34m(arrays, names, axes)\u001b[0m\n\u001b[1;32m   1753\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1754\u001b[0m         \u001b[0mblock_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_block_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1755\u001b[0;31m         \u001b[0mitems_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblock_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1757\u001b[0m     \u001b[0mblocks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mBlock\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results, metrics = {}, {}\n",
    "for name, model in zip(names, models):\n",
    "    print(name)\n",
    "    results[name], metrics[name] = {}, {}\n",
    "    for data, scenario in zip(datas, scenarios):\n",
    "        _start_time = datetime.now()\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "            results[name][scenario], metrics[name][scenario] = model.run(**data)\n",
    "        \n",
    "        _time_elapsed = datetime.now() - _start_time\n",
    "        print(f\"{scenario} — total time elapsed {_time_elapsed}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "regression_df = pd.DataFrame()\n",
    "member_ids = metrics[\"GAM_NOTadjusted\"][1][\"member_ids\"]\n",
    "battery_ids = metrics[\"GAM_NOTadjusted\"][1][\"batt_ids\"]\n",
    "GAMresults = results[\"GAM_NOTadjusted\"][1]\n",
    "Perfectresults = results[\"Perfect\"][1]\n",
    "netload = lambda x, member_id, prefix: (x[f\"{prefix}cons_{member_id}\"] - x[f\"{prefix}prod_{member_id}\"])\n",
    "\n",
    "# Training data\n",
    "for member_id, battery_id in zip(member_ids, battery_ids):\n",
    "    df = pd.DataFrame()\n",
    "    df[\"time\"] = GAMresults.index\n",
    "    df[\"hour\"] = df[\"time\"].dt.hour\n",
    "    df[\"member_id\"] = member_id\n",
    "    \n",
    "    # SOC\n",
    "    df[\"soc\"] = GAMresults[f\"_batt_{battery_id}_kwh\"].values\n",
    "    df[\"soc_*\"] = Perfectresults[f\"_batt_{battery_id}_kwh\"].values\n",
    "    \n",
    "    # Individual netload\n",
    "    df[\"netload_kw\"] = netload(GAMresults, member_id, \"\").values\n",
    "    df[\"f_netload_kw\"] = netload(GAMresults, member_id, \"f\").values\n",
    "    df[\"epsilon\"] = df[\"netload_kw\"] - df[\"f_netload_kw\"]\n",
    "    \n",
    "    # Decision\n",
    "    df[\"u_*\"] = Perfectresults[f\"obatt_{battery_id}\"].values\n",
    "    df[\"u\"] = GAMresults[f\"obatt_{battery_id}\"].values\n",
    "    df[\"u_ind\"] = df[[\"u\", \"netload_kw\"]].apply(\n",
    "        lambda x: MatchSurplus._split_individual_collective(x.netload_kw, x.u)[0], axis=1)\n",
    "    df[\"u_virtual\"] = df[[\"u\", \"netload_kw\"]].apply(\n",
    "        lambda x: MatchSurplus._split_individual_collective(x.netload_kw, x.u)[1], axis=1)\n",
    "\n",
    "    regression_df = pd.concat([regression_df, df], axis=0, ignore_index=True)\n",
    "\n",
    "# An idea on the remaining for me at the community level\n",
    "tmp = []\n",
    "for member_id in member_ids:\n",
    "    _ = regression_df[regression_df.member_id != member_id].groupby(\"time\")[\"u\"].sum()\n",
    "    tmp.extend(_)\n",
    "regression_df[f\"sum_u_notme_netload\"] = tmp\n",
    "\n",
    "# Add community epsilon\n",
    "sum_epsilon = regression_df.groupby(\"time\")[\"epsilon\"].sum()\n",
    "regression_df[\"sum_epsilon\"] = [*sum_epsilon.values] * len(member_ids)\n",
    "netload_kw = regression_df.groupby(\"time\")[\"netload_kw\"].sum()\n",
    "regression_df[\"sum_netload_kw\"] = [*netload_kw.values] * len(member_ids)\n",
    "f_netload_kw = regression_df.groupby(\"time\")[\"f_netload_kw\"].sum()\n",
    "regression_df[\"sum_f_netload_kw\"] = [*f_netload_kw.values] * len(member_ids)\n",
    "regression_df[\"u_netload\"] = regression_df[\"u\"] + regression_df[\"netload_kw\"]\n",
    "u_virtual = regression_df.groupby(\"time\")[\"u\"].sum()\n",
    "regression_df[\"sum_u_netload\"] = [*u_virtual.values] * len(member_ids)\n",
    "regression_df[\"sum_u_netload\"] += regression_df[\"sum_netload_kw\"]\n",
    "regression_df[f\"sum_u_notme_netload\"] += regression_df[\"sum_netload_kw\"]\n",
    "\n",
    "view_columns = [\"time\", \"hour\", \"member_id\", \"u_*\", \"u\", \"u_ind\", \"u_virtual\",\n",
    "               \"soc_*\", \"soc\", \"netload_kw\", \"f_netload_kw\"]\n",
    "print(list(regression_df.columns))\n",
    "regression_df[view_columns].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split and score functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "def split_train_test(regression_df, member_id, test_start, soc_threshold=500):\n",
    "    # Select the right member and resample to 15 min\n",
    "    member_df = regression_df[regression_df.member_id == member_id].copy()\n",
    "    member_df.set_index(\"time\", inplace=True)\n",
    "    member_df = member_df.resample(\"15T\").first()\n",
    "    member_df.reset_index(inplace=True)\n",
    "    \n",
    "    # Filter based on SOC threshold ?\n",
    "    battery_kwh = 5.0\n",
    "    mask_df = member_df.copy()\n",
    "    mask_df = mask_df[(mask_df[\"soc_*\"] - mask_df[\"soc\"]).abs()\n",
    "                      * 100 / battery_kwh < soc_threshold]\n",
    "    \n",
    "    # Split train and test\n",
    "    train_df = mask_df.copy()\n",
    "    train_df.set_index(\"time\", inplace=True)\n",
    "    train_df = train_df.loc[:test_start - timedelta(minutes=15)]\n",
    "    train_df.reset_index(inplace=True)\n",
    "    \n",
    "    test_df = member_df.copy()\n",
    "    test_df.set_index(\"time\", inplace=True)\n",
    "    test_df = test_df.loc[test_start:test_start + timedelta(hours=23, minutes=45)]\n",
    "    test_df.reset_index(inplace=True)\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "def score(test_df, adjust_model, features):\n",
    "    prior_error = test_df[\"u_*\"].values - test_df[\"u\"].values\n",
    "    error_after = test_df[\"u_*\"].values - adjust_model.predict(test_df[features].values)\n",
    "    errors = pd.DataFrame(data={\"Uhat=U (before)\": prior_error, \"Uhat=g() (after)\": error_after})\n",
    "    \n",
    "    # (Error with U - Error with g()) * 100 / Error with U\n",
    "    score = round((errors['Uhat=U (before)'].abs().sum() -\n",
    "                   errors['Uhat=g() (after)'].abs().sum()) * 100 /\n",
    "                   errors['Uhat=U (before)'].abs().sum(), 2)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Illustrate best parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "LinearTreeRegressor(\n",
    "    base_estimator=LinearRegression(),\n",
    "    max_depth=5,\n",
    "    linear_features=[\n",
    "        features.index(\"u\"),\n",
    "        features.index(\"netload_kw\"),\n",
    "        features.index(\"sum_netload_kw\"),\n",
    "        features.index(\"epsilon\"),\n",
    "    ],\n",
    "    split_features=[\n",
    "        features.index(\"soc\"),\n",
    "        features.index(\"netload_kw\"),\n",
    "        features.index(\"sum_u_notme_netload\")\n",
    "    ],\n",
    "    min_samples_leaf=0.1, max_bins=25)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from lineartree import LinearTreeRegressor\n",
    "\n",
    "test_date_range = [start + timedelta(days=x) for x in range(29, 29+7)]\n",
    "features = [\n",
    " 'hour',        \n",
    " 'soc',           \n",
    " 'netload_kw',      \n",
    " 'f_netload_kw',    \n",
    " 'epsilon',       \n",
    " 'u',\n",
    " 'u_ind',           \n",
    " 'u_virtual',        \n",
    " 'sum_epsilon',    \n",
    " 'sum_netload_kw', \n",
    " 'sum_f_netload_kw',\n",
    " 'u_netload', \n",
    " 'sum_u_netload',\n",
    " \"sum_u_notme_netload\"\n",
    "]\n",
    "\n",
    "# Model definition\n",
    "# ################\n",
    "adjust_model = LinearTreeRegressor(\n",
    "    base_estimator=LinearRegression(),\n",
    "    max_depth=5,\n",
    "    linear_features=[\n",
    "        features.index(\"u\"),\n",
    "        features.index(\"netload_kw\"),\n",
    "        features.index(\"sum_netload_kw\"),\n",
    "        features.index(\"epsilon\"),\n",
    "    ],\n",
    "    split_features=[\n",
    "        features.index(\"soc\"),\n",
    "        features.index(\"netload_kw\"),\n",
    "        features.index(\"sum_u_notme_netload\")\n",
    "    ],\n",
    "    min_samples_leaf=0.1, max_bins=25)\n",
    "# ################\n",
    "\n",
    "scores = {\"member_id\": [], \"score\": []}\n",
    "for member_id in regression_df.member_id.unique():\n",
    "    for start_test in test_date_range:\n",
    "        # Split and filter data\n",
    "        train_df, test_df = split_train_test(\n",
    "            regression_df, member_id=member_id, test_start=start_test)\n",
    "        \n",
    "        # Fit model\n",
    "        adjust_model = adjust_model.fit(train_df[features].values, train_df[\"u_*\"].values)\n",
    "        \n",
    "        # Score\n",
    "        scores[\"member_id\"].append(member_id)\n",
    "        scores[\"score\"].append(score(test_df, adjust_model, features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Score\n",
    "graph = pd.DataFrame(scores)\n",
    "graph.drop(columns=\"member_id\", inplace=True)\n",
    "print(f\"Median value {round(graph.score.median(), 2)} %\")\n",
    "\n",
    "\n",
    "_fig = px.histogram(graph[graph.score > -100], histnorm=\"percent\", nbins=10)\n",
    "_fig.update_traces(marker_opacity=0.7, marker_line_color=\"black\", marker_line_width=2)\n",
    "\n",
    "_fig.update_layout(\n",
    "    layout, yaxis_title=\"Percentage [%]\",\n",
    "    height=450,\n",
    "    width=850,\n",
    "    xaxis_title=\"Improvement with f() instead of Û to reach U*\",\n",
    "    xaxis_range=[-100, 100])\n",
    "_fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Illustrate another reasonable setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from lineartree import LinearTreeRegressor\n",
    "\n",
    "test_date_range = [start + timedelta(days=x) for x in range(29, 29+7)]\n",
    "features = [\n",
    " 'hour',        \n",
    " 'soc',           \n",
    " 'netload_kw',      \n",
    " 'f_netload_kw',    \n",
    " 'epsilon',       \n",
    " 'u',\n",
    " 'u_ind',           \n",
    " 'u_virtual',        \n",
    " 'sum_epsilon',    \n",
    " 'sum_netload_kw', \n",
    " 'sum_f_netload_kw',\n",
    " 'u_netload', \n",
    " 'sum_u_netload',\n",
    " \"sum_u_notme_netload\"\n",
    "]\n",
    "\n",
    "# Model definition\n",
    "# ################\n",
    "adjust_model = LinearTreeRegressor(\n",
    "    base_estimator=LinearRegression(),\n",
    "    max_depth=5,\n",
    "    linear_features=[\n",
    "        features.index(\"u\"),\n",
    "        #features.index(\"netload_kw\")\n",
    "        #features.index(\"sum_netload_kw\"),\n",
    "        #features.index(\"epsilon\"),\n",
    "    ],\n",
    "    split_features=[\n",
    "        features.index(\"soc\"),\n",
    "        features.index(\"netload_kw\"),\n",
    "        features.index(\"epsilon\")\n",
    "    ],\n",
    "    min_samples_leaf=0.1, max_bins=25)\n",
    "# ################\n",
    "\n",
    "scores = {\"member_id\": [], \"score\": []}\n",
    "for member_id in regression_df.member_id.unique():\n",
    "    for start_test in test_date_range:\n",
    "        # Split and filter data\n",
    "        train_df, test_df = split_train_test(\n",
    "            regression_df, member_id=member_id, test_start=start_test)\n",
    "        \n",
    "        # Fit model\n",
    "        adjust_model = adjust_model.fit(train_df[features].values, train_df[\"u_*\"].values)\n",
    "        \n",
    "        # Score\n",
    "        scores[\"member_id\"].append(member_id)\n",
    "        scores[\"score\"].append(score(test_df, adjust_model, features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "__fig = go.Figure(_fig)\n",
    "\n",
    "graph = pd.DataFrame(scores)\n",
    "graph.drop(columns=\"member_id\", inplace=True)\n",
    "print(f\"Median value {round(graph.score.median(), 2)} %\")\n",
    "\n",
    "for trace in px.histogram(graph[graph.score > -100], histnorm=\"percent\", nbins=10).data:\n",
    "    __fig.add_trace(trace)\n",
    "    __fig.data[-1].update(marker_opacity=0.7, marker_line_color=\"black\", marker_line_width=2)\n",
    "__fig.show()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Jonathan",
   "language": "python",
   "name": "jonathan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "328.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
